---
title: 'ECON 621 Lab #3: Aboli Khairnar'
author: "Aboli Khairnar"
date: "Sept, 2020"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include = FALSE}
source("../functions/load_NLP_env.R")
load_NLP_env("../functions/")

```


```{r}
data <- read.csv("../Capstone/All sector  jobs insights.csv")
data$experience_year <- as.numeric(substr(data$experience, 9, 10))
data$description[1]
table(data$label)
data$reviewerID <- (1:nrow(data))
data$rating <- ifelse(data$jobLevel > 3, 1, 0)
```

Preprocessing the data:
```{r}
text <- pre_process_corpus(data, "description", replace_numbers = T,
                           root_gen = 'lemmatize', extra_stopwords = c("must", "can", "now",  
                                                                       "will"))
```

```{r}
text[1]
data$review_preprocessed  <- text

```

splitting train & test data:
```{r}
rand <- runif(nrow(data))
sets <- ifelse(rand < 0.9, 'train', 'test')

table(sets)

data$set <- sets

train <- data[data$set == 'train',]
```

## Working with a train set:

```{r}
it_train <- itoken(train$review_preprocessed, tokenizer = word_tokenizer, ids = train$reviewerID)
vocab <- create_vocabulary(it_train, c(1,3))

lbound <- round(0.009 * nrow(train))
vocab <- vocab[vocab$doc_count > lbound,]
```

```{r}
dim(vocab)
```
Using vectorizer function:
```{r}
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
```

Sanity check:
```{r}
dim(dtm_train)
```
# 1. Logistic Regression

fitting logistic regression model using cv.glmnet:
Regularization: Lasso (alpha = 1)
```{r}
model_dtm <- cv.glmnet(x = dtm_train, y = train$rating, type.measure = 'auc', 
                       family = 'binomial',
                       alpha = 1)
```


```{r}
coefs <- coef(model_dtm, s = "lambda.min")
coefs <- data.frame(name = coefs@Dimnames[[1]][coefs@i + 1],
                    coefficient = coefs@x)
```

Majority coefficients are zero
```{r}
ggplot(coefs, aes(coefficient)) + geom_histogram(fill = 'lightgreen')
```

```{r}
plot(model_dtm)
max(model_dtm$cvm)
```


## Working with a test set:
```{r}
test <- data[data$set == 'test',] 
it_test <- itoken(test$review_preprocessed, tokenizer = word_tokenizer, ids = test$reviewerID)
dtm_test <- create_dtm(it_test, vectorizer)
dim(dtm_test) 

#predicting the probability
pred_test <- predict(model_dtm, dtm_test, type = 'response')[,1]

head(pred_test)

```

```{r}
thresh <- 0.5
table(test$rating, pred_test > thresh)
glmnet::: auc(test$rating, (pred_test > thresh))
```

# Using Caret:

```{r}
f1 <- function(data, lev = NULL, model = NULL){
  recall <- nrow(data[data[, "obs"] == 1 & data[, "pred"] == 1,])/
    nrow(data[data[, "obs"] == 1,])
  precision <- nrow(data[data[, "obs"] == 1 & data[, "pred"] == 1,])/
    nrow(data[data[, "pred"] == 1,])
  out <- (2)*(precision * recall)/(precision + recall)
  names(out) <- 'f1'
  out
}
```


```{r}
library(caret)
trctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 5)
```




# 2. SVM

```{r, warning = F}
library(LiblineaR)

model_svm <- train(x = as.matrix(dtm_train),
                 y = as.factor(train$rating),
                 method = "svmLinearWeights2",
                 trControl = trctrl,
                 tuneGrid = data.frame(cost = 1, Loss = 0, weight = 1)
                 )

pred_test <- predict(model_svm, as.matrix(dtm_test))

preds <- data.frame(id = data$reviewerID[data$set == "test"], 
                    label = data$rating[data$set == "test"],
                    svm = as.numeric(as.character(pred_test)))

auc_svm <- glmnet:::auc(preds$label, as.numeric(as.character(pred_test)))
auc_svm
```

# 3. Naive Bayes

```{r, warning= F}
library(naivebayes)

model_nb <- train(x = as.matrix(dtm_train),
                y = as.factor(train$rating),
                method = "naive_bayes",
                trControl = trctrl,
                tuneGrid = data.frame(laplace = 0, usekernel = FALSE, adjust = FALSE))

pred_test <- predict(model_nb, as.matrix(dtm_test))

preds$nb <- as.numeric(as.character(pred_test))

auc_nb <- glmnet:::auc(preds$label, as.numeric(as.character(pred_test)))
auc_nb
```


# 4. Random Forest

```{r, warning=F}
library(caTools)

model_rf <- train(as.matrix(dtm_train),
            y = as.factor(train$rating),
            method = "ranger",
            trControl = trctrl,
            tuneGrid = data.frame(mtry = floor(sqrt(dim(as.matrix(dtm_train))[2])),
                            splitrule = "gini",
                            min.node.size = 1))

pred_test <- predict(model_rf, as.matrix(dtm_test))

preds$rf <- as.numeric(as.character(pred_test))

auc_rf <- glmnet:::auc(preds$label, as.numeric(as.character(pred_test)))
auc_rf
```

```{r}

tunegrid <-expand.grid(
                        .mtry = 4:15,
                        .splitrule = "gini",
                        .min.node.size = c(1,5,10,15))
model_rf <- train(as.matrix(dtm_train),
            y = as.factor(train$rating),
            method = "ranger",
            trControl =trctrl,
            tuneGrid = tunegrid,
            num.trees = 100)
```


```{r}
#print(model_rf)
plot(model_rf)
```

```{r}
pred_test <- predict(model_rf, as.matrix(dtm_test))
preds <- data.frame(id = data$reviewerID[data$set == "test"], 
                    label = data$rating[data$set == "test"],
                    svm = as.numeric(as.character(pred_test)))

preds$rf <- as.numeric(as.character(pred_test))

auc_rf <- glmnet:::auc(preds$label, as.numeric(as.character(pred_test)))
auc_rf

```

# 5. Neural Network

```{r, results="hide", echo = T}
hidden_layer_size <- 4
tunegrid <-expand.grid(.size = c(3,4,5),
                       .decay = c(1,0.1,0.01)
                       )

nn_model <- train(x =as.matrix(dtm_train), y =  as.factor(train$rating),
                  method = "nnet",
                  trControl = trctrl,
                  tuneGrid =data.frame(size = c(2,3,4), decay = c(0.1, 0.01,0.001)),
                  MaxNWts = hidden_layer_size*(ncol(dtm_train) + 1) + hidden_layer_size  + 1)
```
```{r}
pred_test <- predict(nn_model, as.matrix(dtm_test))
preds <- data.frame(id = data$reviewerID[data$set == "test"], 
                    label = data$rating[data$set == "test"],
                    svm = as.numeric(as.character(pred_test)))

preds$rf <- as.numeric(as.character(pred_test))

auc_rf <- glmnet:::auc(preds$label, as.numeric(as.character(pred_test)))
auc_rf
```


Imbalanced classes:
```{r}
table(train$rating)
```
```{r, warning=F}
it <- itoken(data$review_preprocessed, tokenizer = word_tokenizer, ids = data$reviewerID)
vocab <- create_vocabulary(it, c(1,3))

lbound <- round(0.009 * nrow(data))
vocab <- vocab[vocab$doc_count > lbound,]
vectorizer <- vocab_vectorizer(vocab)
dtm <- create_dtm(it, vectorizer)

duties_dfm <- dfm(text, remove = stopwords("english"), stem = TRUE, verbose = TRUE)
duties_df <- as.data.frame(duties_dfm)

# Cosine distances
duties_dist <- 1-textstat_simil(duties_dfm, margin="document", method="cosine")

# Set seed for reproducible results
set.seed(123)

# t-SNE dimensionality reduction of cosine distances
duties_tsne <- Rtsne(as.matrix(duties_dist), theta=0, is_distance=TRUE)

# Addition of job classes
duties_tsne <- cbind(data$name, duties_tsne$Y %>% data.frame())

# Addition of challenging classes (T/F)
duties_tsne <- duties_tsne %>% mutate(Challenging_class=ifelse(data$name %in% c("Data Scientist"), TRUE, FALSE))

# Plot
plot <- ggplot(duties_tsne, aes(x=X1, y=X2)) + geom_point(aes(color=Challenging_class, text=data$name), size=2, alpha=0.6) + theme_blank() + theme(legend.position="none") + ggtitle("Job duties") + scale_color_manual(values=c("TRUE"="coral3", "FALSE"="chartreuse4"), name="Challenging class")

# Interactive plot
plot %>% ggplotly(tooltip="text") %>% layout(yaxis=list(scaleanchor="x")) 
```
```{r}


plot <- plot %>% ggplotly(tooltip="text") %>% layout(yaxis=list(scaleanchor="x"))

htmlwidgets::saveWidget(as_widget(plot), "index.html")
```

```{r}
hc <- hclust(as.dist(duties_dist), "ward.D")

clustering <- cutree(hc, 20)

plot(hc, main = "Hierarchical clustering of 100 NIH grant abstracts",
     ylab = "", xlab = "", yaxt = "n")

rect.hclust(hc, 20, border = "red")
```
```{r}
p_words <- colSums(dtm) / sum(dtm)

cluster_words <- lapply(unique(clustering), function(x){
  rows <- dtm[ clustering == x , ]
  
  # for memory's sake, drop all words that don't appear in the cluster
  rows <- rows[ , colSums(rows) > 0 ]
  
  colSums(rows) / sum(rows) - p_words[ colnames(rows) ]
})
```

```{r}
# create a summary table of the top 5 words defining each cluster
cluster_summary <- data.frame(cluster = unique(clustering),
                              size = as.numeric(table(clustering)),
                              top_words = sapply(cluster_words, function(d){
                                paste(
                                  names(d)[ order(d, decreasing = TRUE) ][ 1:5 ], 
                                  collapse = ", ")
                              }),
                              stringsAsFactors = FALSE)
#cluster_summary


```


```{r}
sparse_corpus <- Matrix(dtm, sparse = T)
```

```{r, results='hide', echo=T}
# converting matrix into document-level list of vocab counts
docs <- apply(dtm, 1, function(x){
  tmp <- as.data.frame(x)
  tmp$vocab <- 1:nrow(tmp)
  tmp <- tmp[tmp[,1] >0,]
  tmp <- as.matrix.data.frame(t(tmp[, c(2,1)]))
  return(tmp)
})

# running ksearch function and analyze results
ksearch <- searchK(documents = docs, vocab = colnames(dtm), K = c(5:25))
```

```{r}
df <- data.frame(K = c(5:25), residual = unlist(ksearch$results$residual))
ggplot(data = df, aes(y = residual, x = K)) + geom_point()

par(mar=c(1,1,1,1))

```


```{r, results="hide", echo = T}
topic_model2 <- stm(sparse_corpus, init.type = 'LDA', seed = 12345,
                   K = 23, control = list(alpha = 64))

topic_prevalence <- as.data.frame(topic_model2$theta)
mean(apply(topic_prevalence, 1, max))
topic_content <- as.data.frame(t(exp(topic_model2$beta$logbeta[[1]])))
topic_names <- apply(topic_content, 2, function(x) {paste(topic_model2$vocab[order(x,
                                      decreasing = T)[1:6]], collapse = " ")})
topic_names
```
```{r, include=F, results= F}
table(data$careerArea)
```

```{r}
df <- topic_prevalence
colnames(df) <- topic_names
df$name <- as.character(data$name)
df <- melt(df, id.vars = 'name', value.name = 'proportion', variable.name = 'topic')

ggplot(df[df$name == 'Tile / Granite Worker',], aes(x = topic, y = proportion, fill = topic)) + geom_bar(stat = 'identity') +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank(), legend.position = "top") +  
  coord_flip() + facet_wrap(~(name))
```
```{r}
temp_df <- df %>% group_by(name) %>% mutate(max = max(proportion))
temp_df <- temp_df %>% group_by(name) %>% filter(proportion == max) 

temp_df <- temp_df[order(temp_df$name),]
data <- data[order(data$name),]

data$topic <- temp_df$topic
```

```{r, include = F}
head(data)
```


```{r}
# Possible job paths 
paths <- data %>% select(name, topic, experience_year) %>% unique()

# Convert to graph
paths_graph <- graph.data.frame(paths, directed=TRUE)

# Set seed for reproducible results
set.seed(150)

# Network building
paths_net <- ggnetwork::ggnetwork(paths_graph, layout= with_fr(), arrow.gap=0.002
                                 )

# Network plot
ggplot(paths_net, aes(x=x, y=y, xend=xend, yend=yend)) + geom_edges(arrow=arrow(length=unit(1, 'mm'), type="closed"), color="grey30") + geom_nodes(color="dodgerblue3") + theme_blank() + theme(aspect.ratio=1) + ggtitle("Job paths network")
```

```{r}
# Clusters (subnetworks) from the graph
graph_clusters <- clusters(paths_graph)
graph_clusters <- data.frame(graph_clusters$membership)
graph_clusters$JOB_CLASS <- rownames(graph_clusters)

```

```{r}
# Link the cluster number to the job classes
paths_net$Subnet <- graph_clusters$graph_clusters.membership[match(paths_net$name,graph_clusters$JOB_CLASS)]

# Top subnet sizes
paths_net %>% count(Subnet) %>% arrange(desc(n)) %>% head(10)

```

```{r}
ggplot(paths_net, aes(x=x, y=y, xend=xend, yend=yend)) + geom_edges(arrow=arrow(length=unit(1, 'mm'), type="closed"), color="grey70") + geom_nodes(aes(color=ifelse(Subnet %in% c(1), TRUE, FALSE))) + theme_blank() + theme(aspect.ratio=1, legend.position="none") + ggtitle("Job paths subnetworks") + scale_color_manual(values=c("TRUE"="dodgerblue3", "FALSE"="grey70"))
```
```{r}
ggplot(paths_net %>% filter(Subnet==6), aes(x=x, y=y, xend=xend, yend=yend)) + geom_edges(arrow=arrow(length=unit(2, 'mm'), type="closed"), size=1, color="darkgrey") + geom_nodes(color="dodgerblue3", size=3) + geom_nodetext_repel(aes(label=name), size=3) + theme_blank() + theme(aspect.ratio=1) + ggtitle("Job paths (subnetwork 5)")
```


```{r}
png("sub5.png", width = 800, height = 600)
ggplot(paths_net %>% filter(Subnet==6), aes(x=x, y=y, xend=xend, yend=yend)) + geom_edges(arrow=arrow(length=unit(2, 'mm'), type="closed"), size=1, color="darkgrey") + geom_nodes(color="dodgerblue3", size=3) + geom_nodetext_repel(aes(label=name), size=3) + theme_blank() + theme(aspect.ratio=1) + ggtitle("Job paths (subnetwork 5)")
dev.off()
```

```{r}

ggplot(paths_net %>% filter(Subnet==1, experience_year == 3), aes(x=x, y=y, xend=xend, yend=yend)) + geom_edges(arrow=arrow(length=unit(2, 'mm'), type="closed"), size=1, color="darkgrey") + geom_nodes(color="dodgerblue3", size=3) + geom_nodetext_repel(aes(label=name), size=3) + theme_blank() + theme(aspect.ratio=1) + ggtitle("Job paths (subnetwork 5)")

```

```{r}
ggplot(paths_net %>% filter(Subnet==6, experience_year == 4), aes(x=x, y=y, xend=xend, yend=yend)) + geom_edges(arrow=arrow(length=unit(2, 'mm'), type="closed"), size=1, color="darkgrey") + geom_nodes(color="dodgerblue3", size=3) + geom_nodetext_repel(aes(label=name), size=3) + theme_blank() + theme(aspect.ratio=1) + ggtitle("Job paths (subnetwork 5)")

```
